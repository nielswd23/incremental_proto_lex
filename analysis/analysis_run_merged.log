nohup: ignoring input
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.1     ✔ stringr   1.5.2
✔ ggplot2   4.0.0     ✔ tibble    3.3.0
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.1.0     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

Attaching package: ‘tidylog’

The following objects are masked from ‘package:dplyr’:

    add_count, add_tally, anti_join, count, distinct, distinct_all,
    distinct_at, distinct_if, filter, filter_all, filter_at, filter_if,
    full_join, group_by, group_by_all, group_by_at, group_by_if,
    inner_join, left_join, mutate, mutate_all, mutate_at, mutate_if,
    relocate, rename, rename_all, rename_at, rename_if, rename_with,
    right_join, sample_frac, sample_n, select, select_all, select_at,
    select_if, semi_join, slice, slice_head, slice_max, slice_min,
    slice_sample, slice_tail, summarise, summarise_all, summarise_at,
    summarise_if, summarize, summarize_all, summarize_at, summarize_if,
    tally, top_frac, top_n, transmute, transmute_all, transmute_at,
    transmute_if, ungroup

The following objects are masked from ‘package:tidyr’:

    drop_na, fill, gather, pivot_longer, pivot_wider, replace_na,
    separate_wider_delim, separate_wider_position,
    separate_wider_regex, spread, uncount

The following object is masked from ‘package:stats’:

    filter

Loading required package: Rcpp
Loading 'brms' package (version 2.23.0). Useful instructions
can be found by typing help('brms'). A more detailed introduction
to the package is available through vignette('brms_overview').

Attaching package: ‘brms’

The following object is masked from ‘package:stats’:

    ar


Attaching package: ‘tidybayes’

The following object is masked from ‘package:bayestestR’:

    hdi

The following objects are masked from ‘package:brms’:

    dstudent_t, pstudent_t, qstudent_t, rstudent_t

Loading required package: viridisLite
Loading required package: lattice

Attaching package: ‘caret’

The following object is masked from ‘package:purrr’:

    lift

group_by: 2 grouping variables (model, fold)
summarise: now 135 rows and 3 columns, ungrouped
[1] "All models have matching unigram, bigram, and both contrast files for each fold."
[1] "working on current model PhilipsPearl_DPS_Unigram"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.1e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 9e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.9 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8.8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.88 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.5e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.441 seconds (Warm-up)
Chain 4:                0.372 seconds (Sampling)
Chain 4:                0.813 seconds (Total)
Chain 4: 
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.478 seconds (Warm-up)
Chain 1:                0.389 seconds (Sampling)
Chain 1:                0.867 seconds (Total)
Chain 1: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.474 seconds (Warm-up)
Chain 3:                0.399 seconds (Sampling)
Chain 3:                0.873 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.518 seconds (Warm-up)
Chain 2:                0.398 seconds (Sampling)
Chain 2:                0.916 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.5e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.4e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.418 seconds (Warm-up)
Chain 4:                0.296 seconds (Sampling)
Chain 4:                0.714 seconds (Total)
Chain 4: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.46 seconds (Warm-up)
Chain 2:                0.291 seconds (Sampling)
Chain 2:                0.751 seconds (Total)
Chain 2: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.447 seconds (Warm-up)
Chain 3:                0.294 seconds (Sampling)
Chain 3:                0.741 seconds (Total)
Chain 3: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.438 seconds (Warm-up)
Chain 1:                0.381 seconds (Sampling)
Chain 1:                0.819 seconds (Total)
Chain 1: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.3e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.395 seconds (Warm-up)
Chain 3:                0.298 seconds (Sampling)
Chain 3:                0.693 seconds (Total)
Chain 3: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.428 seconds (Warm-up)
Chain 1:                0.33 seconds (Sampling)
Chain 1:                0.758 seconds (Total)
Chain 1: 
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.458 seconds (Warm-up)
Chain 2:                0.374 seconds (Sampling)
Chain 2:                0.832 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.456 seconds (Warm-up)
Chain 4:                0.353 seconds (Sampling)
Chain 4:                0.809 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.6500000 0.6196970 0.6818182   0.95 median       hdi              1
2 0.5893939 0.5545455 0.6257576   0.95 median       hdi              1
3 0.6757576 0.6469697 0.7090909   0.95 median       hdi              1
  p_above_random OverlapWithRandom             list                    model
1        1.00000       0.007931530 unigram_contrast PhilipsPearl_DPS_Unigram
2        0.69575       0.080124021  bigram_contrast PhilipsPearl_DPS_Unigram
3        1.00000       0.001668492    both_contrast PhilipsPearl_DPS_Unigram
[1] "working on current model PhilipsPearl_Ideal_Bigram_Batch"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.87 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.2e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8.7e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.87 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 8e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.435 seconds (Warm-up)
Chain 2:                0.335 seconds (Sampling)
Chain 2:                0.77 seconds (Total)
Chain 2: 
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.464 seconds (Warm-up)
Chain 1:                0.359 seconds (Sampling)
Chain 1:                0.823 seconds (Total)
Chain 1: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.438 seconds (Warm-up)
Chain 4:                0.347 seconds (Sampling)
Chain 4:                0.785 seconds (Total)
Chain 4: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.456 seconds (Warm-up)
Chain 3:                0.394 seconds (Sampling)
Chain 3:                0.85 seconds (Total)
Chain 3: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.2e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.4e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.43 seconds (Warm-up)
Chain 1:                0.272 seconds (Sampling)
Chain 1:                0.702 seconds (Total)
Chain 1: 
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.418 seconds (Warm-up)
Chain 4:                0.246 seconds (Sampling)
Chain 4:                0.664 seconds (Total)
Chain 4: 
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.45 seconds (Warm-up)
Chain 2:                0.297 seconds (Sampling)
Chain 2:                0.747 seconds (Total)
Chain 2: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.484 seconds (Warm-up)
Chain 3:                0.291 seconds (Sampling)
Chain 3:                0.775 seconds (Total)
Chain 3: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.5e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.85 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.9e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.5e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.464 seconds (Warm-up)
Chain 1:                0.295 seconds (Sampling)
Chain 1:                0.759 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.423 seconds (Warm-up)
Chain 3:                0.344 seconds (Sampling)
Chain 3:                0.767 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.415 seconds (Warm-up)
Chain 2:                0.38 seconds (Sampling)
Chain 2:                0.795 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.455 seconds (Warm-up)
Chain 4:                0.35 seconds (Sampling)
Chain 4:                0.805 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.7181818 0.6909091 0.7469697   0.95 median       hdi              1
2 0.6000000 0.5651515 0.6333333   0.95 median       hdi              1
3 0.6931818 0.6666667 0.7257576   0.95 median       hdi              1
  p_above_random OverlapWithRandom             list
1         1.0000      0.0001578527 unigram_contrast
2         0.8755      0.0556132648  bigram_contrast
3         1.0000      0.0006705626    both_contrast
                            model
1 PhilipsPearl_Ideal_Bigram_Batch
2 PhilipsPearl_Ideal_Bigram_Batch
3 PhilipsPearl_Ideal_Bigram_Batch
[1] "working on current model PhilipsPearl_Ideal_Bigram_Online"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.1e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.3e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.73 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.455 seconds (Warm-up)
Chain 3:                0.289 seconds (Sampling)
Chain 3:                0.744 seconds (Total)
Chain 3: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.457 seconds (Warm-up)
Chain 1:                0.352 seconds (Sampling)
Chain 1:                0.809 seconds (Total)
Chain 1: 
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.483 seconds (Warm-up)
Chain 4:                0.274 seconds (Sampling)
Chain 4:                0.757 seconds (Total)
Chain 4: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.511 seconds (Warm-up)
Chain 2:                0.346 seconds (Sampling)
Chain 2:                0.857 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.84 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0.000128 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.28 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8.3e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.49 seconds (Warm-up)
Chain 4:                0.249 seconds (Sampling)
Chain 4:                0.739 seconds (Total)
Chain 4: 
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.517 seconds (Warm-up)
Chain 1:                0.318 seconds (Sampling)
Chain 1:                0.835 seconds (Total)
Chain 1: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.493 seconds (Warm-up)
Chain 2:                0.337 seconds (Sampling)
Chain 2:                0.83 seconds (Total)
Chain 2: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.502 seconds (Warm-up)
Chain 3:                0.338 seconds (Sampling)
Chain 3:                0.84 seconds (Total)
Chain 3: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.8e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.4e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.84 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.5e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.485 seconds (Warm-up)
Chain 1:                0.331 seconds (Sampling)
Chain 1:                0.816 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.51 seconds (Warm-up)
Chain 3:                0.358 seconds (Sampling)
Chain 3:                0.868 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.527 seconds (Warm-up)
Chain 2:                0.407 seconds (Sampling)
Chain 2:                0.934 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.516 seconds (Warm-up)
Chain 4:                0.405 seconds (Sampling)
Chain 4:                0.921 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.6075758 0.5742424 0.6409091   0.95 median       hdi         1.0000
2 0.5530303 0.5166667 0.5878788   0.95 median       hdi         0.9975
3 0.6227273 0.5878788 0.6560606   0.95 median       hdi         1.0000
  p_above_random OverlapWithRandom             list
1        0.95275        0.04104079 unigram_contrast
2        0.07975        0.15538945  bigram_contrast
3        0.99250        0.02594264    both_contrast
                             model
1 PhilipsPearl_Ideal_Bigram_Online
2 PhilipsPearl_Ideal_Bigram_Online
3 PhilipsPearl_Ideal_Bigram_Online
[1] "working on current model PhilipsPearl_Ideal_Unigram_Batch"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0.000137 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.37 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.9e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.579 seconds (Warm-up)
Chain 2:                0.394 seconds (Sampling)
Chain 2:                0.973 seconds (Total)
Chain 2: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.57 seconds (Warm-up)
Chain 1:                0.433 seconds (Sampling)
Chain 1:                1.003 seconds (Total)
Chain 1: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.579 seconds (Warm-up)
Chain 3:                0.399 seconds (Sampling)
Chain 3:                0.978 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.552 seconds (Warm-up)
Chain 4:                0.408 seconds (Sampling)
Chain 4:                0.96 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.77 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.3e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.6e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.443 seconds (Warm-up)
Chain 2:                0.216 seconds (Sampling)
Chain 2:                0.659 seconds (Total)
Chain 2: 
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.407 seconds (Warm-up)
Chain 1:                0.282 seconds (Sampling)
Chain 1:                0.689 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.394 seconds (Warm-up)
Chain 3:                0.313 seconds (Sampling)
Chain 3:                0.707 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.434 seconds (Warm-up)
Chain 4:                0.262 seconds (Sampling)
Chain 4:                0.696 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.6e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.86 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 8.1e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.462 seconds (Warm-up)
Chain 1:                0.374 seconds (Sampling)
Chain 1:                0.836 seconds (Total)
Chain 1: 
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.446 seconds (Warm-up)
Chain 2:                0.381 seconds (Sampling)
Chain 2:                0.827 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.463 seconds (Warm-up)
Chain 4:                0.367 seconds (Sampling)
Chain 4:                0.83 seconds (Total)
Chain 4: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.459 seconds (Warm-up)
Chain 3:                0.416 seconds (Sampling)
Chain 3:                0.875 seconds (Total)
Chain 3: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.6696970 0.6378788 0.7015152   0.95 median       hdi              1
2 0.5833333 0.5484848 0.6196970   0.95 median       hdi              1
3 0.6787879 0.6484848 0.7090909   0.95 median       hdi              1
  p_above_random OverlapWithRandom             list
1         1.0000       0.002961540 unigram_contrast
2         0.5785       0.093704938  bigram_contrast
3         1.0000       0.001645092    both_contrast
                             model
1 PhilipsPearl_Ideal_Unigram_Batch
2 PhilipsPearl_Ideal_Unigram_Batch
3 PhilipsPearl_Ideal_Unigram_Batch
[1] "working on current model PhilipsPearl_Ideal_Unigram_Online"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.84 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.9e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.8e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.529 seconds (Warm-up)
Chain 1:                0.372 seconds (Sampling)
Chain 1:                0.901 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.539 seconds (Warm-up)
Chain 3:                0.348 seconds (Sampling)
Chain 3:                0.887 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.54 seconds (Warm-up)
Chain 2:                0.398 seconds (Sampling)
Chain 2:                0.938 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.546 seconds (Warm-up)
Chain 4:                0.385 seconds (Sampling)
Chain 4:                0.931 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.7e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.77 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.4e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.567 seconds (Warm-up)
Chain 1:                0.321 seconds (Sampling)
Chain 1:                0.888 seconds (Total)
Chain 1: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.51 seconds (Warm-up)
Chain 4:                0.313 seconds (Sampling)
Chain 4:                0.823 seconds (Total)
Chain 4: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.524 seconds (Warm-up)
Chain 3:                0.366 seconds (Sampling)
Chain 3:                0.89 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.553 seconds (Warm-up)
Chain 2:                0.365 seconds (Sampling)
Chain 2:                0.918 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.2e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.7e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.77 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.532 seconds (Warm-up)
Chain 2:                0.38 seconds (Sampling)
Chain 2:                0.912 seconds (Total)
Chain 2: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.552 seconds (Warm-up)
Chain 1:                0.416 seconds (Sampling)
Chain 1:                0.968 seconds (Total)
Chain 1: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.549 seconds (Warm-up)
Chain 3:                0.401 seconds (Sampling)
Chain 3:                0.95 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.527 seconds (Warm-up)
Chain 4:                0.417 seconds (Sampling)
Chain 4:                0.944 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.5984848 0.5651515 0.6318182   0.95 median       hdi        1.00000
2 0.5515152 0.5106061 0.5848485   0.95 median       hdi        0.99425
3 0.6000000 0.5696970 0.6363636   0.95 median       hdi        1.00000
  p_above_random OverlapWithRandom             list
1        0.84650        0.05921052 unigram_contrast
2        0.06000        0.15756308  bigram_contrast
3        0.89175        0.05365961    both_contrast
                              model
1 PhilipsPearl_Ideal_Unigram_Online
2 PhilipsPearl_Ideal_Unigram_Online
3 PhilipsPearl_Ideal_Unigram_Online
[1] "working on current model PUDDLE"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.8e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.2e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8.2e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 8.2e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.425 seconds (Warm-up)
Chain 1:                0.361 seconds (Sampling)
Chain 1:                0.786 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.468 seconds (Warm-up)
Chain 2:                0.346 seconds (Sampling)
Chain 2:                0.814 seconds (Total)
Chain 2: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.434 seconds (Warm-up)
Chain 3:                0.392 seconds (Sampling)
Chain 3:                0.826 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.491 seconds (Warm-up)
Chain 4:                0.388 seconds (Sampling)
Chain 4:                0.879 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.6e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.419 seconds (Warm-up)
Chain 3:                0.236 seconds (Sampling)
Chain 3:                0.655 seconds (Total)
Chain 3: 
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.41 seconds (Warm-up)
Chain 1:                0.379 seconds (Sampling)
Chain 1:                0.789 seconds (Total)
Chain 1: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.394 seconds (Warm-up)
Chain 4:                0.316 seconds (Sampling)
Chain 4:                0.71 seconds (Total)
Chain 4: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.429 seconds (Warm-up)
Chain 2:                0.35 seconds (Sampling)
Chain 2:                0.779 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.4e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.84 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.3e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.3e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.73 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.8e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.392 seconds (Warm-up)
Chain 1:                0.248 seconds (Sampling)
Chain 1:                0.64 seconds (Total)
Chain 1: 
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.429 seconds (Warm-up)
Chain 2:                0.346 seconds (Sampling)
Chain 2:                0.775 seconds (Total)
Chain 2: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.447 seconds (Warm-up)
Chain 3:                0.362 seconds (Sampling)
Chain 3:                0.809 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.457 seconds (Warm-up)
Chain 4:                0.37 seconds (Sampling)
Chain 4:                0.827 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.6984848 0.6681818 0.7287879   0.95 median       hdi              1
2 0.6196970 0.5878788 0.6545455   0.95 median       hdi              1
3 0.7272727 0.6984848 0.7545455   0.95 median       hdi              1
  p_above_random OverlapWithRandom             list  model
1        1.00000      0.0005641882 unigram_contrast PUDDLE
2        0.99125      0.0286302084  bigram_contrast PUDDLE
3        1.00000      0.0001160509    both_contrast PUDDLE
[1] "working on current model RandomBaseline"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.2e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.3e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.73 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.6e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.495 seconds (Warm-up)
Chain 1:                0.407 seconds (Sampling)
Chain 1:                0.902 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.523 seconds (Warm-up)
Chain 3:                0.412 seconds (Sampling)
Chain 3:                0.935 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.522 seconds (Warm-up)
Chain 2:                0.439 seconds (Sampling)
Chain 2:                0.961 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.515 seconds (Warm-up)
Chain 4:                0.425 seconds (Sampling)
Chain 4:                0.94 seconds (Total)
Chain 4: 
[1] "kfolding"
Error in getGlobalsAndPackages(expr, envir = envir, globals = globals) : 
  The total size of the 17 globals exported for future expression (‘FUN()’) is 503.85 MiB. This exceeds the maximum allowed size 500.00 MiB per by R option "future.globals.maxSize". This limit is set to protect against transfering too large objects to parallel workers by mistake, which may not be intended and could be costly. See help("future.globals.maxSize", package = "future") for further explainations and how to adjust or remove this threshold The three largest globals are ‘FUN’ (172.38 MiB of class ‘function’), ‘up_args’ (166.44 MiB of class ‘list’) and ‘newdata’ (165.02 MiB of class ‘list’)
Calls: fit_and_predict_bayesian ... getGlobalsAndPackagesXApply -> getGlobalsAndPackages
In addition: There were 37 warnings (use warnings() to see them)
Execution halted
