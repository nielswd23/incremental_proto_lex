nohup: ignoring input
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.1     ✔ stringr   1.5.2
✔ ggplot2   4.0.0     ✔ tibble    3.3.0
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.1.0     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

Attaching package: ‘tidylog’

The following objects are masked from ‘package:dplyr’:

    add_count, add_tally, anti_join, count, distinct, distinct_all,
    distinct_at, distinct_if, filter, filter_all, filter_at, filter_if,
    full_join, group_by, group_by_all, group_by_at, group_by_if,
    inner_join, left_join, mutate, mutate_all, mutate_at, mutate_if,
    relocate, rename, rename_all, rename_at, rename_if, rename_with,
    right_join, sample_frac, sample_n, select, select_all, select_at,
    select_if, semi_join, slice, slice_head, slice_max, slice_min,
    slice_sample, slice_tail, summarise, summarise_all, summarise_at,
    summarise_if, summarize, summarize_all, summarize_at, summarize_if,
    tally, top_frac, top_n, transmute, transmute_all, transmute_at,
    transmute_if, ungroup

The following objects are masked from ‘package:tidyr’:

    drop_na, fill, gather, pivot_longer, pivot_wider, replace_na,
    separate_wider_delim, separate_wider_position,
    separate_wider_regex, spread, uncount

The following object is masked from ‘package:stats’:

    filter

Loading required package: Rcpp
Loading 'brms' package (version 2.23.0). Useful instructions
can be found by typing help('brms'). A more detailed introduction
to the package is available through vignette('brms_overview').

Attaching package: ‘brms’

The following object is masked from ‘package:stats’:

    ar


Attaching package: ‘tidybayes’

The following object is masked from ‘package:bayestestR’:

    hdi

The following objects are masked from ‘package:brms’:

    dstudent_t, pstudent_t, qstudent_t, rstudent_t

Loading required package: viridisLite
Loading required package: lattice

Attaching package: ‘caret’

The following object is masked from ‘package:purrr’:

    lift

group_by: 2 grouping variables (model, fold)
summarise: now 135 rows and 3 columns, ungrouped
[1] "All models have matching unigram, bigram, and both contrast files for each fold."
[1] "working on current model SmallCMU_Klattese"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 9.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.97 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 9.4e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.94 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8.8e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.88 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.9 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.513 seconds (Warm-up)
Chain 1:                0.407 seconds (Sampling)
Chain 1:                0.92 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.561 seconds (Warm-up)
Chain 3:                0.4 seconds (Sampling)
Chain 3:                0.961 seconds (Total)
Chain 3: 
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.54 seconds (Warm-up)
Chain 4:                0.519 seconds (Sampling)
Chain 4:                1.059 seconds (Total)
Chain 4: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.534 seconds (Warm-up)
Chain 2:                0.625 seconds (Sampling)
Chain 2:                1.159 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.8e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.2e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.72 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.409 seconds (Warm-up)
Chain 1:                0.256 seconds (Sampling)
Chain 1:                0.665 seconds (Total)
Chain 1: 
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.459 seconds (Warm-up)
Chain 2:                0.332 seconds (Sampling)
Chain 2:                0.791 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.433 seconds (Warm-up)
Chain 4:                0.332 seconds (Sampling)
Chain 4:                0.765 seconds (Total)
Chain 4: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.432 seconds (Warm-up)
Chain 3:                0.368 seconds (Sampling)
Chain 3:                0.8 seconds (Total)
Chain 3: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.1e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.1e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.71 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.442 seconds (Warm-up)
Chain 1:                0.344 seconds (Sampling)
Chain 1:                0.786 seconds (Total)
Chain 1: 
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.437 seconds (Warm-up)
Chain 2:                0.38 seconds (Sampling)
Chain 2:                0.817 seconds (Total)
Chain 2: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.452 seconds (Warm-up)
Chain 3:                0.386 seconds (Sampling)
Chain 3:                0.838 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.473 seconds (Warm-up)
Chain 4:                0.385 seconds (Sampling)
Chain 4:                0.858 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.7575758 0.7318182 0.7848485   0.95 median       hdi              1
2 0.6333333 0.6015152 0.6666667   0.95 median       hdi              1
3 0.7000000 0.6727273 0.7318182   0.95 median       hdi              1
  p_above_random OverlapWithRandom             list             model
1          1.000      8.084547e-06 unigram_contrast SmallCMU_Klattese
2          0.999      1.563479e-02  bigram_contrast SmallCMU_Klattese
3          1.000      5.680856e-04    both_contrast SmallCMU_Klattese
[1] "working on current model TinyInfantLexiconNoNumbers_Prepped"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.3e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.83 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.1e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.9e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.4e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.427 seconds (Warm-up)
Chain 2:                0.299 seconds (Sampling)
Chain 2:                0.726 seconds (Total)
Chain 2: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.44 seconds (Warm-up)
Chain 4:                0.348 seconds (Sampling)
Chain 4:                0.788 seconds (Total)
Chain 4: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.474 seconds (Warm-up)
Chain 1:                0.396 seconds (Sampling)
Chain 1:                0.87 seconds (Total)
Chain 1: 
Chain 3: 
Chain 3:  Elapsed Time: 0.472 seconds (Warm-up)
Chain 3:                0.366 seconds (Sampling)
Chain 3:                0.838 seconds (Total)
Chain 3: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.5e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.85 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.5e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.75 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.477 seconds (Warm-up)
Chain 2:                0.303 seconds (Sampling)
Chain 2:                0.78 seconds (Total)
Chain 2: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.444 seconds (Warm-up)
Chain 1:                0.359 seconds (Sampling)
Chain 1:                0.803 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.449 seconds (Warm-up)
Chain 3:                0.395 seconds (Sampling)
Chain 3:                0.844 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.481 seconds (Warm-up)
Chain 4:                0.416 seconds (Sampling)
Chain 4:                0.897 seconds (Total)
Chain 4: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.9e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.6e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.438 seconds (Warm-up)
Chain 2:                0.328 seconds (Sampling)
Chain 2:                0.766 seconds (Total)
Chain 2: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.419 seconds (Warm-up)
Chain 4:                0.311 seconds (Sampling)
Chain 4:                0.73 seconds (Total)
Chain 4: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.441 seconds (Warm-up)
Chain 3:                0.326 seconds (Sampling)
Chain 3:                0.767 seconds (Total)
Chain 3: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.441 seconds (Warm-up)
Chain 1:                0.378 seconds (Sampling)
Chain 1:                0.819 seconds (Total)
Chain 1: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.5378788 0.4969697 0.5727273   0.95 median       hdi        0.96850
2 0.5636364 0.5303030 0.6000000   0.95 median       hdi        0.99975
3 0.5863636 0.5500000 0.6212121   0.95 median       hdi        1.00000
  p_above_random OverlapWithRandom             list
1        0.01300        0.16710472 unigram_contrast
2        0.19100        0.14206223  bigram_contrast
3        0.63725        0.08537329    both_contrast
                               model
1 TinyInfantLexiconNoNumbers_Prepped
2 TinyInfantLexiconNoNumbers_Prepped
3 TinyInfantLexiconNoNumbers_Prepped
[1] "working on current model top_22"
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
rename: renamed one variable (KlattbetAdjustedSpaced)
mutate: new variable 'KlattbetAdjusted' (character) with 132 unique values and 0% NA
        new variable 'RS' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
        new variable 'contrast' (character) with one unique value and 0% NA
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in unigram_contrast_addins     0
           > rows only in unigram_contrast_stimuli (  0)
           > matched rows                           660    (includes duplicates)
           >                                       =====
           > rows total                             660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in bigram_contrast_addins     0
           > rows only in bigram_contrast_stimuli (  0)
           > matched rows                          660    (includes duplicates)
           >                                      =====
           > rows total                            660
left_join: added 19 columns (KlattbetAdjustedSpaced, word_len, uni_prob, uni_prob_freq_weighted, bi_prob, …)
           > rows only in both_contrast_addins     0
           > rows only in both_contrast_stimuli (  0)
           > matched rows                        660    (includes duplicates)
           >                                    =====
           > rows total                          660
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 8.5e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.85 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8.2e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.82 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 8.1e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.81 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.6e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.52 seconds (Warm-up)
Chain 2:                0.395 seconds (Sampling)
Chain 2:                0.915 seconds (Total)
Chain 2: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.532 seconds (Warm-up)
Chain 3:                0.379 seconds (Sampling)
Chain 3:                0.911 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.522 seconds (Warm-up)
Chain 4:                0.372 seconds (Sampling)
Chain 4:                0.894 seconds (Total)
Chain 4: 
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.564 seconds (Warm-up)
Chain 1:                0.41 seconds (Sampling)
Chain 1:                0.974 seconds (Total)
Chain 1: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.7e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.77 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 7.9e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.4e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.8e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.496 seconds (Warm-up)
Chain 1:                0.33 seconds (Sampling)
Chain 1:                0.826 seconds (Total)
Chain 1: 
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.5 seconds (Warm-up)
Chain 3:                0.354 seconds (Sampling)
Chain 3:                0.854 seconds (Total)
Chain 3: 
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.526 seconds (Warm-up)
Chain 4:                0.376 seconds (Sampling)
Chain 4:                0.902 seconds (Total)
Chain 4: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.551 seconds (Warm-up)
Chain 2:                0.392 seconds (Sampling)
Chain 2:                0.943 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
[1] "more than one RS value"
[1] "fitting main model"
Compiling Stan program...
Start sampling

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 7.8e-05 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.78 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 8e-05 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 7.4e-05 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.74 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 7.9e-05 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.79 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0.505 seconds (Warm-up)
Chain 1:                0.321 seconds (Sampling)
Chain 1:                0.826 seconds (Total)
Chain 1: 
Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 0.486 seconds (Warm-up)
Chain 4:                0.342 seconds (Sampling)
Chain 4:                0.828 seconds (Total)
Chain 4: 
Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 0.46 seconds (Warm-up)
Chain 3:                0.401 seconds (Sampling)
Chain 3:                0.861 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 0.497 seconds (Warm-up)
Chain 2:                0.394 seconds (Sampling)
Chain 2:                0.891 seconds (Total)
Chain 2: 
[1] "kfolding"
Fitting model 1 out of 10
Start sampling
Fitting model 2 out of 10
Start sampling
Fitting model 3 out of 10
Start sampling
Fitting model 4 out of 10
Start sampling
Fitting model 5 out of 10
Start sampling
Fitting model 6 out of 10
Start sampling
Fitting model 7 out of 10
Start sampling
Fitting model 8 out of 10
Start sampling
Fitting model 9 out of 10
Start sampling
Fitting model 10 out of 10
Start sampling
[1] "kfold predicting"
rename: renamed one variable (DrawNum)
pivot_longer: reorganized (1, 2, 3, 4, 5, …) into (ItemClassID, Predicted) [was 4000x661, now 2640000x3]
rename: renamed 2 variables (ItemClassID, GroundTruth)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
[1] "reading in the null model"
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
ungroup: no grouping variables remain
select: dropped one variable (DrawNum)
rename: renamed one variable (OverlapWithRandom)
Joining with `by = join_by(ItemClassID)`
left_join: added one column (GroundTruth)
           > rows only in preds            0
           > rows only in actuals (        0)
           > matched rows          2,640,000
           >                      ===========
           > rows total            2,640,000
mutate: new variable 'Correct' (double) with 2 unique values and 0% NA
group_by: one grouping variable (DrawNum)
summarise: now 4,000 rows and 2 columns, ungrouped
select: dropped one variable (DrawNum)
mutate: new variable 'is_above_chance' (double) with 2 unique values and 0% NA
        new variable 'p_above_chance' (double) with one unique value and 0% NA
        new variable 'p_above_random' (double) with one unique value and 0% NA
select: dropped 2 variables (accuracy, is_above_chance)
distinct: removed 3,999 rows (>99%), one row remaining
mutate: new variable 'list' (character) with one unique value and 0% NA
        new variable 'model' (character) with one unique value and 0% NA
[1] "returning results"
   accuracy    .lower    .upper .width .point .interval p_above_chance
1 0.5166667 0.4787879 0.5530303   0.95 median       hdi        0.81000
2 0.5181818 0.4818182 0.5560606   0.95 median       hdi        0.83125
3 0.5439394 0.5060606 0.5787879   0.95 median       hdi        0.98925
  p_above_random OverlapWithRandom             list  model
1        0.00075         0.1696588 unigram_contrast top_22
2        0.00075         0.1684404  bigram_contrast top_22
3        0.02675         0.1638040    both_contrast top_22
There were 22 warnings (use warnings() to see them)
